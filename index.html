<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Communication-Avoiding Parallel Sparse-Dense Matrix Multiplication &#x2014; The MPI Programming Assignment</title>
<!-- 2019-05-14 Tue 15:30 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Krzysztof Rzadca" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js", "[Contrib]/siunitx/siunitx.js", "[Contrib]/mhchem/mhchem.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        TeX: {extensions: ["AMSmath.js","AMSsymbols.js",  "[Contrib]/siunitx/siunitx.js", "[Contrib]/mhchem/mhchem.js"]},
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Communication-Avoiding Parallel Sparse-Dense Matrix Multiplication &#x2014; The MPI Programming Assignment</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">1. Introduction</a></li>
<li><a href="#sec-2">2. Communication-Avoding Sparse-Dense Matrix Multiplication</a></li>
<li><a href="#sec-3">3. Specific requirements</a></li>
<li><a href="#sec-4">4. Input and output</a></li>
<li><a href="#sec-5">5. Solution content</a></li>
<li><a href="#sec-6">6. Scoring</a></li>
<li><a href="#sec-7">7. Additional materials</a></li>
<li><a href="#sec-8">8. FAQ</a></li>
</ul>
</div>
</div>
<p>
Due date: 2 June 2019
</p>

<p>
Version of this document: 1
</p>

<p>
changelog:
</p>
<ul class="org-ul">
<li>2019/05/14 first version published
</li>
</ul>



<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
As in a typical supercomputer communication takes orders of magnitude more time than computation, there is a growing new field in high-performance algorithms: communication-avoidance. These algorithms trade communication for redundant computation or increased memory usage.
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2"><span class="section-number-2">2</span> Communication-Avoding Sparse-Dense Matrix Multiplication</h2>
<div class="outline-text-2" id="text-2">
<p>
Your goal is to implement two parallel algorithms for multiplying a sparse matrix A by a dense matrix B: 1.5D Blocked Column A; and 1.5D Blocked Inner ABC - see the paper by Koanantakool et al. 
The main idea of both algorithms is to replicate (redundantly) the data, and then to do less communication rounds, than if the data were not replicated.
Both algorithms organize processes into "replication" groups of size c (c is a parameter of the algorithm).
The Column A algorithm replicates just the sparse matrix A. The Inner ABC algorithm replicates all the matrices: the result C is gathered from the parts stored in the replication group.
</p>

<p>
Note: there are two errors in Koanantakool et al's paper. (1) In the description of 1.5D Blocked Inner ABC the paper defines the C's blocks to be computed by process P(j,l) as \(C^{p/c \times p/c}(k,j) = A^{p/c \times 1}(k,:) B^{1 \times p/c} (:,j)\) where \(lq \leq k < (l+1)q\), however, this contradicts the description that follows and the example from Fig 3.b. The correct indexing is: \(k \mod p/c\) such that \(lq +j \leq k < (l+1)q + j\). (2) There is a similar error in the description of Column A: P(j) stores \(A^{1 \times p/c}(:,j \mod p/c)\) (which is consistent with Fig. 2b), and not \(A^{1 \times p/c}(:,j)\).
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3"><span class="section-number-2">3</span> Specific requirements</h2>
<div class="outline-text-2" id="text-3">
<p>
Your goal is to implement multiple matrix multiplication, i.e., compute \(C = A ( A ( A ... ( A B ) ) )\). You cannot change the order of multiplications. The number of multiplications is given as a program parameter.
</p>

<p>
Your implementation must start from a data distribution for c = 1 (i.e., as if there is no replication). Using a generator we supply, processes generate the dense matrix B in parallel (our generator is stateless, so it might be used in parallel by multiple MPI processes; however, each element of the matrix must be generated exactly once).
</p>

<p>
Process 0 loads the sparse matrix A from a CSR file (see bibliography for the description of the format) and then sends it to other processes. Each process should receive only a part of the matrix that it will store for data distribution for c = 1 (the coordinator should not send redundant data).
</p>

<p>
Only after this initial data distribution, processes should contact their peers in replication groups and exchange their parts of matrices.
</p>

<p>
Write two versions of your program. In a basic version, do not use any libraries for local (inside a process) matrix multiplication. In a second version, use MKL for local matrix multiplication.
</p>

<p>
Assume that A and B are square matrices.
</p>

<p>
Assume that, for performance testing, the number of rows and columns of A is much larger (at least thousands) than the number of MPI processes (at most hundreds). However, you cannot assume that the number of MPI processes divides the number of rows/columns (but you can extend matrices with 0 rows or columns, as long as they do not get printed in the final result).
</p>
</div>
</div>

<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4"><span class="section-number-2">4</span> Input and output</h2>
<div class="outline-text-2" id="text-4">
<p>
Programs will be tested automatically. Please stick to the format below.
</p>

<p>
Your program will be run using the following instructions:
</p>

<p>
<code>cd xx123456; rm -rf build; mkdir build; cd build; cmake ..; make</code>
</p>

<p>
<code>srun ./matrixmul -f sparse_matrix_file -s seed_for_dense_matrix -c repl_group_size -e exponent [-g ge_value] [-v] [-i] [-m]</code>
</p>

<p>
where:
</p>
<ul class="org-ul">
<li><code>sparse_matrix_file</code> is a CSR file storing the sparse matrix A. The first row contains 4 integers: the number of rows, the number of columns, the total number of non-zero elements, and the maximum number of non-zero elements in each row. The following 3 rows specify entries (array A in wikipedia's description); row offsets (array IA); and column indices (array JA).
</li>
<li><code>-i</code> toggles the Inner algorithm (otherwise the Column algorithm is used);
</li>
<li><code>-v</code> prints the matrix C (the multiplication result) in the row-major order: the first line specifies the number of rows and the number of columns of the result; i+1-th line is the i-th row of the matrix;
</li>
<li><code>-c repl_group_size</code> specifies the number of processes in each replication group (i.e., parameter c from Koanantakool et al);
</li>
<li><code>-e exponent</code> the number of multiplications to do, e.g., for <code>-e 3</code> your program should compute \(C = A ( A ( A B ) )\)
</li>
<li><code>-g ge_value</code> prints the number of elements in C greater than or equal to the <code>ge_value</code>.
</li>
<li><code>-m</code> turns on MKL for in-process sparse-dense matrix multiplication (it's off by default).
</li>
</ul>

<p>
Do not print anything other than the matrix C (if <code>-v</code> is used) or a single integer (if <code>-g</code> is used) on stdout.
</p>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5"><span class="section-number-2">5</span> Solution content</h2>
<div class="outline-text-2" id="text-5">
<p>
Please send us a single <code>.zip</code> file containing a single directory with your login (<code>ab123456</code>); the directory has at least the following files:
</p>
<ul class="org-ul">
<li><code>densematgen.h</code>: our generator. This file cannot be modified.
</li>
<li><code>densematgen.cpp</code>: our generator. This file cannot be modified. For tests, we might use a different implementation of the generator (but it will be stateless);
</li>
<li><code>report.pdf</code>: a report describing your implementation. Estimate the numerical intensity of the problem (as in the roofline model). Describe the optimizations you implemented. Show weak and strong scaling results. For scaling, find instances and input parameters so that the measurements are realistic, but the (wall clock) run time does not exceed 3 minutes when more than 4 nodes are used. 
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6"><span class="section-number-2">6</span> Scoring</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li>correct MPI implementation of the Inner algorithm: 6 points;
</li>
<li>correct MPI implementation of the Column algorithm: 6 points;
</li>
<li>report: 4 points (incorrect implementations do not get these points);
</li>
<li>performance: 9 points (incorrect implementations do not get these points).
</li>
</ul>

<p>
We will score correctness on our test data; we take into account the floating point errors. If your solution passes most of the tests, but fails on some, we will contact you and you will be able to submit a patched version.
</p>

<p>
We will use Okeanos for performance testing.
</p>

<p>
To optimize performance, consider using advanced MPI operations, like asynchronous messages, collectives, custom datatypes, custom communicators (hint: for communicating inside a replication group). Remember to test the MKL library. You may also consider using OpenMP.
</p>

<p>
Our performance tests will use <code>--tasks-per-node 24</code> unless you write in your report that your solution is more efficient with other value (e.g., you use MPI+OpenMP and you just need <code>--tasks-per-node 1</code> or <code>--tasks-per-node 2</code>).
</p>

<p>
Please do submit your assignment by the due date. If you're late, your score will be reduced by 1 point for every 12 hours (i.e.: if you're late by 2h, we subtract 1 point from your score; if you're late by 25h, we subtract 3 points).
</p>

<p>
There is a second due date - 13th June. Submitting by this due date is very risky. First, very good solutions submitted by this due date receive minimum passing score (i.e.: at most 10 points). Second, there will be less time for patching. Please do submit your assignment by the normal, first due date.
</p>
</div>
</div>

<div id="outline-container-sec-7" class="outline-2">
<h2 id="sec-7"><span class="section-number-2">7</span> Additional materials</h2>
<div class="outline-text-2" id="text-7">
<p>
Please do not use any source codes of matrix multiplication programs. We recommend reading the following documents:
</p>

<ul class="org-ul">
<li>P.Koanantakool et al, Communication-Avoiding Parallel Sparse-Dense Matrix-Matrix Multiplication, IPDPS 2016, <a href="http://www.eecs.berkeley.edu/~penpornk/spdm3_ipdps16.pdf">http://www.eecs.berkeley.edu/~penpornk/spdm3_ipdps16.pdf</a>
</li>

<li>Jesper Larsson Traff, William D. Gropp, and Rajeev Thakur, Self-Consistent MPI Performance Guidelines <a href="http://www-unix.mcs.anl.gov/~thakur/papers/tpds-consistency.pdf">http://www-unix.mcs.anl.gov/~thakur/papers/tpds-consistency.pdf</a>
</li>

<li>CSR matrix format: <a href="https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29">https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29</a>
</li>

<li>our generator: <a href="mat-generator.zip">mat-generator.zip</a>
</li>

<li>some tests: <a href="mat-tests.zip">mat-tests.zip</a>
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-8" class="outline-2">
<h2 id="sec-8"><span class="section-number-2">8</span> FAQ</h2>
<div class="outline-text-2" id="text-8">
<ul class="org-ul">
<li>What language can I use?
</li>
</ul>

<p>
C or C++.
</p>

<ul class="org-ul">
<li>What datatype should I use for computation?
</li>
</ul>

<p>
Use doubles.
</p>

<ul class="org-ul">
<li>Do you really want us to, first, scatter A into as many unique pieces as there are processes, and only after that (if \(c>1\)) construct redundant A parts by communicating among processes? Why can't the coordinator send A partitioned for correct c?
</li>
</ul>

<p>
Matrix multiplication (and other distributed) algorithms commonly assume that the data is partioned evenly among processes before the algorithm starts (see the first lecture on alpha-beta efficiency model). The communication-avoiding algorithms reorganize data and thus add new communication (before the multiplication really begins). We want to be able to measure the time needed for this additional communication, which is possible only when the algorithm firstly distributes the data for c=1 (thus, as if there was no communication-avoidance), and only after that reorganizes the data.
</p>

<ul class="org-ul">
<li>Can process 0 load the whole sparse matrix A, and only after that partition it and send parts to other processes?
</li>
</ul>

<p>
Yes it can.
</p>

<ul class="org-ul">
<li>What is the c parameter? Number of processes in the replication group, or number of replication groups? And what is a replication group anyway?
</li>
</ul>

<p>
In this document, a replication group is a group of processes storing the same data (after replication phase, before the computation phase). In the replication phase, each process contacts \((c-1)\) other processes; these processes combine the data they got from the initial data distribution.
</p>

<ul class="org-ul">
<li>Can I assume that the resulting C will fit in the memory of a single node?
</li>
</ul>

<p>
In general: if <code>-g</code> or no output option is used, you can't assume the result will fit in a single node. But you can assume that if <code>-v</code> is used, C will fit in a single node.
</p>

<ul class="org-ul">
<li>Can I assume that, when InnerABC is used, \(p\) is a multiply of \(c^2\) 
</li>
</ul>

<p>
Yes, you can.
</p>

<ul class="org-ul">
<li>How should the processes know the size of matrix A?
</li>
</ul>

<p>
Process 0 can broadcast the size of A. In general, you can add messages to your implementation.
</p>

<ul class="org-ul">
<li>How are the example tests organized? 
</li>
</ul>

<p>
<code>result_X_000Y_Z_A</code> is a result of multiplying <code>sparse05_000Y_Z</code> with <code>matrix01_000Y_A</code> X times (i.e., with <code>-e X</code>). For instance, in <code>result_2_00010_002_00291</code>, we multiply <code>sparse05_00010_002</code> with <code>matrix01_00010_291</code> and then mutliply the result again by <code>sparse05_00010_002</code>, or, in other words, <code>./matrixmul -f sparse05_0010_002 -s 291 -e 2 -v</code>.
</p>

<ul class="org-ul">
<li>Can a process temporary store a few (two, three) blocks of matrix A (e.g., when the matrix is shifted)?
</li>
</ul>

<p>
Yes, it can.
</p>

<ul class="org-ul">
<li>How should the output be formatted?
</li>
</ul>

<p>
See the description of <code>-v</code> in the Input/Output section. Additional instructions: white-spaces are not important (values can be separated by a single space); field formatting is not important; you should use a standard format for floating point numbers (eg. <code>12345.67890</code>) with at least 5 numbers after the dot.
</p>

<ul class="org-ul">
<li>Can I destroy B during computation?
</li>
</ul>

<p>
Yes, you can (as long as the result is correct).
</p>

<ul class="org-ul">
<li>In Inner, at the end, should the processes send their parts of matrix to process in layer 0, or can they directly send the parts to the coordinator (or just the counts for <code>-g</code>)?
</li>
</ul>

<p>
For fair measurements, please reduce first to layer 0, and only then send to the coordinator.
</p>

<ul class="org-ul">
<li>Can the coordinator allocate memory for 2|A|?
</li>
</ul>

<p>
Yes, it can.
</p>

<ul class="org-ul">
<li>Can we assume that the cluster nodes will use the same binary representation of numbers?
</li>
</ul>

<p>
Yes, you can.
</p>

<ul class="org-ul">
<li>Can I use a different matrix representation for the sparse matrix A?
</li>
</ul>

<p>
The input is in CSR, but you can use any internal (i.e., in memory) representation, including CSR. The representation has to be sparse, i.e., A cannot use \(O(n^2)\) memory.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Krzysztof Rzadca</p>
<p class="date">Created: 2019-05-14 Tue 15:30</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.3.50.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
